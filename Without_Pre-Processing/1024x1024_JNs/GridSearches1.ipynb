{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118a4cf6-3ac1-4f51-9ed3-755f24c3dc3c",
   "metadata": {},
   "source": [
    "Smaller Starting Point Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507b95ed-0dc1-4f3f-9303-6d3af8fef1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 1022, 1022, 32)    320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 511, 511, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 509, 509, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 254, 254, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 252, 252, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 126, 126, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2032128)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               520225024 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520318467 (1.94 GB)\n",
      "Trainable params: 520318467 (1.94 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 186 images belonging to 3 classes.\n",
      "Found 63 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5/5 [==============================] - 34s 6s/step - loss: 33.7427 - accuracy: 0.3506 - val_loss: 2.8781 - val_accuracy: 0.3438\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 2.0969 - accuracy: 0.3766 - val_loss: 1.6700 - val_accuracy: 0.3438\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 27s 5s/step - loss: 1.3031 - accuracy: 0.3247 - val_loss: 1.0690 - val_accuracy: 0.4062\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 28s 5s/step - loss: 1.1737 - accuracy: 0.4545 - val_loss: 1.1200 - val_accuracy: 0.3438\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.0618 - accuracy: 0.4375 - val_loss: 0.9446 - val_accuracy: 0.4688\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.9129 - accuracy: 0.6299 - val_loss: 1.0829 - val_accuracy: 0.4375\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.8766 - accuracy: 0.6558 - val_loss: 1.2484 - val_accuracy: 0.4688\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.1145 - accuracy: 0.5688 - val_loss: 1.0544 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.7494 - accuracy: 0.7078 - val_loss: 1.3050 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.6261 - accuracy: 0.7857 - val_loss: 1.1386 - val_accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = 'C:\\\\Users\\\\Alexandra\\\\Documents\\\\SPRING_2024\\\\BMEN_689\\\\Project_2\\\\Jupyter_Notebook\\\\1024x1024_Phage_EMs\\\\'\n",
    "\n",
    "# Function to split dataset into train/validation/test\n",
    "def split_dataset(data_folder, train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    for class_folder in os.listdir(data_folder):\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            files = os.listdir(class_path)\n",
    "            train_files, test_files = train_test_split(files, test_size=val_size+test_size, random_state=42)\n",
    "            val_files, test_files = train_test_split(test_files, test_size=test_size/(val_size+test_size), random_state=42)\n",
    "\n",
    "            train_folder = os.path.join(data_folder, 'train', class_folder)\n",
    "            val_folder = os.path.join(data_folder, 'validation', class_folder)\n",
    "            test_folder = os.path.join(data_folder, 'test', class_folder)\n",
    "            for folder in [train_folder, val_folder, test_folder]:\n",
    "                if not os.path.exists(folder):\n",
    "                    os.makedirs(folder)\n",
    "\n",
    "            for file in train_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(train_folder, file))\n",
    "            for file in val_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(val_folder, file))\n",
    "            for file in test_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(test_folder, file))\n",
    "\n",
    "split_dataset(dataset_folder)\n",
    "\n",
    "# Define the simplified CNN model\n",
    "def create_condensed_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Adjusted for grayscale images\n",
    "input_shape = (1024, 1024, 1)\n",
    "num_classes = 3\n",
    "\n",
    "model = create_condensed_cnn(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define directory paths\n",
    "train_dir = os.path.join(dataset_folder, 'train')\n",
    "validation_dir = os.path.join(dataset_folder, 'validation')\n",
    "test_dir = os.path.join(dataset_folder, 'test')\n",
    "\n",
    "# ImageDataGenerator with normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (1024, 1024)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3f06c-8ff3-4987-8353-ea759fc7aa35",
   "metadata": {},
   "source": [
    "Grid Searches for Conv2D and MaxPooling2D Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29dfae3-5563-4aee-a9e1-b53a7f99973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 03m 04s]\n",
      "val_accuracy: 0.40625\n",
      "\n",
      "Best val_accuracy So Far: 0.65625\n",
      "Total elapsed time: 00h 21m 23s\n",
      "\n",
      "The optimal number of layers is 3.\n",
      "The optimal number of filters for each layer are: [64, 32, 32].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = 'C:\\\\Users\\\\Alexandra\\\\Documents\\\\SPRING_2024\\\\BMEN_689\\\\Project_2\\\\Jupyter_Notebook\\\\1024x1024_Phage_EMs\\\\'\n",
    "split_dataset(dataset_folder)  # Assuming this function is defined elsewhere\n",
    "\n",
    "# Define the hypermodel class\n",
    "class ConvolutionalHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=self.input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        # Number of Conv2D+MaxPooling2D layer pairs\n",
    "        for i in range(hp.Int('num_layers', 3, 10)):\n",
    "            model.add(layers.Conv2D(filters=hp.Choice(f'filters_{i}', [32, 64, 128, 256]), kernel_size=(3, 3), activation='relu'))\n",
    "            model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(units=256, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "# Adjusted for grayscale images\n",
    "input_shape = (1024, 1024, 1)\n",
    "num_classes = 3\n",
    "\n",
    "hypermodel = ConvolutionalHyperModel(input_shape, num_classes)\n",
    "\n",
    "# Define directory paths\n",
    "train_dir = os.path.join(dataset_folder, 'train')\n",
    "validation_dir = os.path.join(dataset_folder, 'validation')\n",
    "\n",
    "# ImageDataGenerator with normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (1024, 1024)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Initialize the Random Search\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Adjust based on computational resources\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='cnn_tuning'\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The optimal number of layers is {best_hps.get('num_layers')}.\n",
    "The optimal number of filters for each layer are: {\n",
    "    [best_hps.get(f'filters_{i}') for i in range(best_hps.get('num_layers'))]\n",
    "}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669da9d0-4b80-460f-8faa-011a88cc76dd",
   "metadata": {},
   "source": [
    "Grid Search for Dense and Dropout Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee6caf3-85a2-4fd3-b9d6-fa6be2bed485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 53s]\n",
      "val_accuracy: 0.625\n",
      "\n",
      "Best val_accuracy So Far: 0.625\n",
      "Total elapsed time: 00h 28m 57s\n",
      "Optimal number of dense layers: 3\n",
      "Layer 1: 256 units, with dropout rate: 0.1\n",
      "Layer 2: 32 units\n",
      "Layer 3: 32 units\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the function to split the dataset is defined elsewhere\n",
    "\n",
    "# Define the hypermodel for the dense layers\n",
    "class DenseHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "\n",
    "        # Hyperparameters for the dense layers\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 4)):\n",
    "            model.add(layers.Dense(hp.Int(f'dense_{i}_units', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "            if hp.Boolean(f'dropout_{i}_include'):\n",
    "                model.add(layers.Dropout(hp.Float(f'dropout_{i}_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "        \n",
    "        model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "input_shape = (1024, 1024, 1)  # Adjusted for grayscale images\n",
    "num_classes = 3\n",
    "\n",
    "hypermodel = DenseHyperModel(input_shape, num_classes)\n",
    "\n",
    "# Directory paths\n",
    "dataset_folder = 'C:\\\\Users\\\\Alexandra\\\\Documents\\\\SPRING_2024\\\\BMEN_689\\\\Project_2\\\\Jupyter_Notebook\\\\1024x1024_Phage_EMs\\\\'\n",
    "train_dir = os.path.join(dataset_folder, 'train')\n",
    "validation_dir = os.path.join(dataset_folder, 'validation')\n",
    "\n",
    "# Data preparation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (1024, 1024)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Tuner setup\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Adjust based on your computational resources\n",
    "    executions_per_trial=1,\n",
    "    directory='dense_layers_tuning',\n",
    "    project_name='cnn_dense_tuning'\n",
    ")\n",
    "\n",
    "# Execute the search\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "num_dense_layers = best_hps.get('num_dense_layers')\n",
    "dense_units = [best_hps.get(f'dense_{i}_units') for i in range(num_dense_layers)]\n",
    "dropout_include = [best_hps.get(f'dropout_{i}_include') for i in range(num_dense_layers)]\n",
    "dropout_rates = [best_hps.get(f'dropout_{i}_rate') if dropout_include[i] else None for i in range(num_dense_layers)]\n",
    "\n",
    "print(f\"Optimal number of dense layers: {num_dense_layers}\")\n",
    "for i, units in enumerate(dense_units):\n",
    "    print(f\"Layer {i+1}: {units} units\", end='')\n",
    "    if dropout_include[i]:\n",
    "        print(f\", with dropout rate: {dropout_rates[i]}\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621594a1-04f9-460c-8fa3-76fd232d1714",
   "metadata": {},
   "source": [
    "Increasing epochs from 10 to 25 doesn't change validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61dec344-dba0-44de-89f4-e23b3e743fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 1022, 1022, 32)    320       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 511, 511, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 509, 509, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 254, 254, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 252, 252, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 126, 126, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2032128)           0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               520225024 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520327075 (1.94 GB)\n",
      "Trainable params: 520327075 (1.94 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 186 images belonging to 3 classes.\n",
      "Found 63 images belonging to 3 classes.\n",
      "Epoch 1/25\n",
      "5/5 [==============================] - 30s 6s/step - loss: 22.2058 - accuracy: 0.3701 - val_loss: 1.3472 - val_accuracy: 0.4375\n",
      "Epoch 2/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 1.1925 - accuracy: 0.3442 - val_loss: 1.0931 - val_accuracy: 0.5312\n",
      "Epoch 3/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.1161 - accuracy: 0.3961 - val_loss: 1.0926 - val_accuracy: 0.3438\n",
      "Epoch 4/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.0867 - accuracy: 0.3247 - val_loss: 1.0408 - val_accuracy: 0.4062\n",
      "Epoch 5/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.0606 - accuracy: 0.4481 - val_loss: 1.0474 - val_accuracy: 0.4375\n",
      "Epoch 6/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.0140 - accuracy: 0.5519 - val_loss: 0.9013 - val_accuracy: 0.6250\n",
      "Epoch 7/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.9489 - accuracy: 0.5779 - val_loss: 1.0332 - val_accuracy: 0.4375\n",
      "Epoch 8/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.8289 - accuracy: 0.6429 - val_loss: 1.2907 - val_accuracy: 0.3750\n",
      "Epoch 9/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.6284 - accuracy: 0.7468 - val_loss: 1.3438 - val_accuracy: 0.4688\n",
      "Epoch 10/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.6425 - accuracy: 0.8247 - val_loss: 1.2374 - val_accuracy: 0.3438\n",
      "Epoch 11/25\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.5010 - accuracy: 0.8438 - val_loss: 1.6648 - val_accuracy: 0.4062\n",
      "Epoch 12/25\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.3948 - accuracy: 0.8750 - val_loss: 1.3070 - val_accuracy: 0.6250\n",
      "Epoch 13/25\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.4481 - accuracy: 0.8896 - val_loss: 1.3716 - val_accuracy: 0.5000\n",
      "Epoch 14/25\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.3149 - accuracy: 0.9091 - val_loss: 1.2112 - val_accuracy: 0.5312\n",
      "Epoch 15/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.2435 - accuracy: 0.9416 - val_loss: 1.5646 - val_accuracy: 0.5000\n",
      "Epoch 16/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1703 - accuracy: 0.9675 - val_loss: 2.2498 - val_accuracy: 0.3438\n",
      "Epoch 17/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.1612 - accuracy: 0.9416 - val_loss: 2.3440 - val_accuracy: 0.4062\n",
      "Epoch 18/25\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0643 - accuracy: 0.9812 - val_loss: 3.1234 - val_accuracy: 0.5625\n",
      "Epoch 19/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.3089 - accuracy: 0.9416 - val_loss: 3.4104 - val_accuracy: 0.5000\n",
      "Epoch 20/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1104 - accuracy: 0.9610 - val_loss: 2.6556 - val_accuracy: 0.4375\n",
      "Epoch 21/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.2200 - accuracy: 0.9481 - val_loss: 2.0822 - val_accuracy: 0.3750\n",
      "Epoch 22/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.2119 - accuracy: 0.9416 - val_loss: 1.7379 - val_accuracy: 0.5938\n",
      "Epoch 23/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.1397 - accuracy: 0.9610 - val_loss: 2.6892 - val_accuracy: 0.4375\n",
      "Epoch 24/25\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0950 - accuracy: 0.9740 - val_loss: 2.6224 - val_accuracy: 0.5625\n",
      "Epoch 25/25\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.0616 - accuracy: 0.9870 - val_loss: 3.4874 - val_accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = 'C:\\\\Users\\\\Alexandra\\\\Documents\\\\SPRING_2024\\\\BMEN_689\\\\Project_2\\\\Jupyter_Notebook\\\\1024x1024_Phage_EMs\\\\'\n",
    "\n",
    "# Function to split dataset into train/validation/test\n",
    "def split_dataset(data_folder, train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    for class_folder in os.listdir(data_folder):\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            files = os.listdir(class_path)\n",
    "            train_files, test_files = train_test_split(files, test_size=val_size+test_size, random_state=42)\n",
    "            val_files, test_files = train_test_split(test_files, test_size=test_size/(val_size+test_size), random_state=42)\n",
    "\n",
    "            train_folder = os.path.join(data_folder, 'train', class_folder)\n",
    "            val_folder = os.path.join(data_folder, 'validation', class_folder)\n",
    "            test_folder = os.path.join(data_folder, 'test', class_folder)\n",
    "            for folder in [train_folder, val_folder, test_folder]:\n",
    "                if not os.path.exists(folder):\n",
    "                    os.makedirs(folder)\n",
    "\n",
    "            for file in train_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(train_folder, file))\n",
    "            for file in val_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(val_folder, file))\n",
    "            for file in test_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(test_folder, file))\n",
    "\n",
    "split_dataset(dataset_folder)\n",
    "\n",
    "# Define the simplified CNN model\n",
    "def create_condensed_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.1),        \n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Adjusted for grayscale images\n",
    "input_shape = (1024, 1024, 1)\n",
    "num_classes = 3\n",
    "\n",
    "model = create_condensed_cnn(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define directory paths\n",
    "train_dir = os.path.join(dataset_folder, 'train')\n",
    "validation_dir = os.path.join(dataset_folder, 'validation')\n",
    "test_dir = os.path.join(dataset_folder, 'test')\n",
    "\n",
    "# ImageDataGenerator with normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (1024, 1024)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "epochs = 25\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8e3b4-30ed-4341-8d28-2a46cf728487",
   "metadata": {},
   "source": [
    "L2 Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f4427f-94e0-4870-845e-00e421eeded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 1022, 1022, 32)    320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 511, 511, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 509, 509, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 254, 254, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 252, 252, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 126, 126, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2032128)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               520225024 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520327075 (1.94 GB)\n",
      "Trainable params: 520327075 (1.94 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 186 images belonging to 3 classes.\n",
      "Found 63 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Alexandra\\anaconda3\\envs\\arenvtools\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "5/5 [==============================] - 30s 6s/step - loss: 18.0874 - accuracy: 0.2987 - val_loss: 3.9985 - val_accuracy: 0.3125\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 2.1055 - accuracy: 0.3506 - val_loss: 1.6450 - val_accuracy: 0.3750\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.7346 - accuracy: 0.4062 - val_loss: 1.8067 - val_accuracy: 0.3438\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.7569 - accuracy: 0.4610 - val_loss: 1.7329 - val_accuracy: 0.4688\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 28s 6s/step - loss: 1.8116 - accuracy: 0.4221 - val_loss: 1.7115 - val_accuracy: 0.5312\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.7237 - accuracy: 0.5063 - val_loss: 1.7276 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1.5942 - accuracy: 0.6313 - val_loss: 2.8325 - val_accuracy: 0.4062\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 1.5008 - accuracy: 0.6875 - val_loss: 2.1273 - val_accuracy: 0.3750\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.3496 - accuracy: 0.7727 - val_loss: 2.3070 - val_accuracy: 0.5312\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.3064 - accuracy: 0.8062 - val_loss: 2.3149 - val_accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "dataset_folder = 'C:\\\\Users\\\\Alexandra\\\\Documents\\\\SPRING_2024\\\\BMEN_689\\\\Project_2\\\\Jupyter_Notebook\\\\1024x1024_Phage_EMs\\\\'\n",
    "\n",
    "# Function to split dataset into train/validation/test\n",
    "def split_dataset(data_folder, train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    for class_folder in os.listdir(data_folder):\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            files = os.listdir(class_path)\n",
    "            train_files, test_files = train_test_split(files, test_size=val_size+test_size, random_state=42)\n",
    "            val_files, test_files = train_test_split(test_files, test_size=test_size/(val_size+test_size), random_state=42)\n",
    "\n",
    "            train_folder = os.path.join(data_folder, 'train', class_folder)\n",
    "            val_folder = os.path.join(data_folder, 'validation', class_folder)\n",
    "            test_folder = os.path.join(data_folder, 'test', class_folder)\n",
    "            for folder in [train_folder, val_folder, test_folder]:\n",
    "                if not os.path.exists(folder):\n",
    "                    os.makedirs(folder)\n",
    "\n",
    "            for file in train_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(train_folder, file))\n",
    "            for file in val_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(val_folder, file))\n",
    "            for file in test_files:\n",
    "                shutil.copy(os.path.join(class_path, file), os.path.join(test_folder, file))\n",
    "\n",
    "split_dataset(dataset_folder)\n",
    "\n",
    "# Define the simplified CNN model\n",
    "def create_condensed_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.0001)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.002)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "        layers.Dropout(0.1),        \n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Adjusted for grayscale images\n",
    "input_shape = (1024, 1024, 1)\n",
    "num_classes = 3\n",
    "\n",
    "model = create_condensed_cnn(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define directory paths\n",
    "train_dir = os.path.join(dataset_folder, 'train')\n",
    "validation_dir = os.path.join(dataset_folder, 'validation')\n",
    "test_dir = os.path.join(dataset_folder, 'test')\n",
    "\n",
    "# ImageDataGenerator with normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "target_size = (1024, 1024)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619807e-9b5c-49c4-b7aa-79486c7abc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
